{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ch5. 在 Unlabeled data 上预训练 LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib version: 3.10.0\n",
      "numpy version: 1.26.4\n",
      "tiktoken version: 0.9.0\n",
      "torch version: 2.2.2\n",
      "tensorflow version: 2.17.0\n"
     ]
    }
   ],
   "source": [
    "# 所需包\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from importlib.metadata import version\n",
    "\n",
    "pkgs = [\"matplotlib\", \n",
    "        \"numpy\", \n",
    "        \"tiktoken\", \n",
    "        \"torch\",\n",
    "        \"tensorflow\" # For OpenAI's pretrained weights (conda install tensorflow)\n",
    "       ]\n",
    "for p in pkgs:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**本章脉络**\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/mental-model--0.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 评价LLM（evaluation）\n",
    "\n",
    "##### 5.1.1 使用LLM生成文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "GPT_CONFIG_124M = {\n",
    "    \"vocab_size\": 50257,   # Vocabulary size\n",
    "    \"context_length\": 256, # Shortened context length (orig: 1024)\n",
    "    \"emb_dim\": 768,        # Embedding dimension\n",
    "    \"n_heads\": 12,         # Number of attention heads\n",
    "    \"n_layers\": 12,        # Number of layers\n",
    "    \"drop_rate\": 0.1,      # Dropout rate\n",
    "    \"qkv_bias\": False      # Query-key-value bias\n",
    "}\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.eval();  # Disable dropout during inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出`[1,4]`的tensor，每个元素代表**当前位置之前tokens生成下一个token的概率分布（使用argmax确定tokenID）**\n",
    "\n",
    "Every                   --->  effort\n",
    "\n",
    "Every effort            --->  moves\n",
    "\n",
    "Every effort moves      --->  you\n",
    "\n",
    "Every effort moves you  --->  forward\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-process.webp\" width=500px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you rentingetic wasnم refres RexMeCHicular stren\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "from previous_chapters import generate_text_simple\n",
    "\n",
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    encoded_tensor = torch.tensor(encoded).unsqueeze(0) # add batch dimension\n",
    "    return encoded_tensor\n",
    "\n",
    "def token_ids_to_text(token_ids, tokenizer):\n",
    "    flat = token_ids.squeeze(0) # remove batch dimension\n",
    "    return tokenizer.decode(flat.tolist())\n",
    "\n",
    "start_context = \"Every effort moves you\"\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "token_ids = generate_text_simple(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(start_context, tokenizer),\n",
    "    max_new_tokens=10,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"]\n",
    ")\n",
    "\n",
    "# 效果不佳，如何评价\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.2 评价指标——交叉熵和困惑度（cross-entropy and perplexity）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[16833, 3626, 6100],   # [\"every effort moves\",\n",
    "                       [40,    1107, 588]])   #  \"I really like\"]\n",
    "\n",
    "targets = torch.tensor([[3626, 6100, 345  ],  # [\" effort moves you\",\n",
    "                        [1107,  588, 11311]]) #  \" really like chocolate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 50257])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    logits = model(inputs)\n",
    "\n",
    "probas = torch.softmax(logits, dim=-1) # Probability of each token in vocabulary\n",
    "print(probas.shape) # Shape: (batch_size, num_tokens, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targets batch 1:  effort moves you\n",
      "Outputs batch 1:  Armed heNetflix\n"
     ]
    }
   ],
   "source": [
    "token_ids = torch.argmax(probas, dim=-1, keepdim=True)\n",
    "\n",
    "print(f\"Targets batch 1: {token_ids_to_text(targets[0], tokenizer)}\")\n",
    "print(f\"Outputs batch 1: {token_ids_to_text(token_ids[0].flatten(), tokenizer)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text 1: tensor([7.4541e-05, 3.1061e-05, 1.1563e-05])\n",
      "Text 2: tensor([1.0337e-05, 5.6776e-05, 4.7559e-06])\n"
     ]
    }
   ],
   "source": [
    "text_idx = 0\n",
    "\"\"\"\n",
    "[0, 0, targets[text_idx][0]]  # every --> effort\n",
    "[0, 1, targets[text_idx][1]]  # every effort --> moves\n",
    "[0, 2, targets[text_idx][2]]  # every effort moves --> you\n",
    "\"\"\"\n",
    "target_probas_1 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 1:\", target_probas_1)\n",
    "\n",
    "text_idx = 1\n",
    "target_probas_2 = probas[text_idx, [0, 1, 2], targets[text_idx]]\n",
    "print(\"Text 2:\", target_probas_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `probas`：模型预测的概率分布，经过了 `softmax`，和为1\n",
    "- 数学优化中，**最大化概率分数的对数**比最大化概率分数本身更容易"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.5042, -10.3796, -11.3677, -11.4798,  -9.7764, -12.2561])\n",
      "tensor(-10.7940)\n"
     ]
    }
   ],
   "source": [
    "log_probas = torch.log(torch.cat((target_probas_1, target_probas_2)))\n",
    "print(log_probas)\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**交叉熵（cross-entropy）**：要让 `avg_log_probas` 越大越好，越接近0越好，实际中一般使用负对数，那么也就变成了越小越好，即 `-avg_log_probas`\n",
    "\n",
    "$\\text{CrossEntropy} = \\mathbb{E}_{x \\sim P} \\left[ -\\log Q(x) \\right]$\n",
    "\n",
    "假设有如下实际分布和预测分布（单一词）：\n",
    "\n",
    "|             | Probas                      |\n",
    "| ----------- | --------------------------- |\n",
    "| Label       | [1, 0, 0, 0, 0]             |\n",
    "| Prediction1 | [0.4, 0.3, 0.05, 0.05, 0.2] |\n",
    "| Prediction2 | [0.98, 0.01, 0, 0, 0.01]    |\n",
    "\n",
    "$H(P_1, Q_1) = - \\sum_i P_1(i) \\log_2 Q_1(i)\n",
    "= -(1 \\log 0.4 + 0 \\log 0.3 + 0 \\log 0.05 + 0 \\log 0.05 + 0 \\log 0.2) \\approx 0.916$\n",
    "\n",
    "$H(P_1, Q_2) = - \\sum_i P_1(i) \\log_2 Q_2(i)\n",
    "= -(1 \\log 0.98 + 0 \\log 0.01 + 0 \\log 0 + 0 \\log 0 + 0 \\log 0.01) \\approx 0.038$\n",
    "\n",
    "那么对于总交叉熵，即 `-avg_log_probas` 这6个预测值的交叉熵之和，可以将每个预测值的 `Label Prediction` 看作 `shape=(50257,)` 的向量，每个预测值的交叉熵即取出的真实token对应位置的 `-log(P)`（其他位置都是0，真实token对应位置是1），对6个交叉熵加和即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- targets 是 tokenID，它们也代表我们想要最大化的 logits 张量中的索引位置\n",
    "- PyTorch 中的 `cross_entropy` 函数将自动负责在要最大化的 logits 中的标记索引上内部应用 softmax 和对数概率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened logits: torch.Size([6, 50257])\n",
      "Flattened targets: torch.Size([6])\n",
      "tensor(10.7940)\n"
     ]
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0, 1)\n",
    "targets_flat = targets.flatten()\n",
    "print(\"Flattened logits:\", logits_flat.shape)\n",
    "print(\"Flattened targets:\", targets_flat.shape)\n",
    "\n",
    "loss = torch.nn.functional.cross_entropy(logits_flat, targets_flat)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**困惑度（perplexity）**：交叉熵的指数形式，越小越好\n",
    "- 困惑度通常被认为更具可解释性，因为它可以理解为模型在每个步骤中不确定的有效词汇量（在下面的例子中，即 48,725 个单词或标记）\n",
    "- 换句话说，困惑度衡量了模型预测的概率分布与数据集中单词的实际分布的匹配程度\n",
    "- 与损失类似，困惑度越低，表示模型预测越接近实际分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(48725.8203)\n"
     ]
    }
   ],
   "source": [
    "perplexity = torch.exp(loss)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.1.3 计算训练集和测试集loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "file_path = \"the-verdict.txt\"\n",
    "url = \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch/main/ch02/01_main-chapter-code/the-verdict.txt\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        text_data = response.read().decode('utf-8')\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(text_data)\n",
    "else:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        text_data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5145\n"
     ]
    }
   ],
   "source": [
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from previous_chapters import create_dataloader_v1\n",
    "\n",
    "# Train/validation ratio\n",
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]\n",
    "\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=GPT_CONFIG_124M[\"context_length\"],\n",
    "    stride=GPT_CONFIG_124M[\"context_length\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
    "    logits = model(input_batch)\n",
    "    \"\"\"\n",
    "    [batch_size * context_length, vocab_size]\n",
    "    [batch_size * context_length]\n",
    "    \"\"\"\n",
    "    loss = torch.nn.functional.cross_entropy(logits.flatten(0, 1), target_batch.flatten())\n",
    "    return loss\n",
    "\n",
    "\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i < num_batches:\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            total_loss += loss.item()\n",
    "        else:\n",
    "            break\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 10.98758316040039\n",
      "Validation loss: 10.98110580444336\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "   device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "   device = torch.device(\"mps\")\n",
    "else:\n",
    "   device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using {device} device.\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "# 节省算力，当前还未开始训练\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 训练LLM（training）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/train-steps.webp\" width=400px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    # Initialize lists to track losses and tokens seen\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    # Main training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward() # Calculate loss gradients\n",
    "            optimizer.step() # Update model weights using loss gradients\n",
    "            # numel返回张量中的元素总数\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Optional evaluation step\n",
    "            if global_step % eval_freq == 0:\n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    model, train_loader, val_loader, device, eval_iter)\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                track_tokens_seen.append(tokens_seen)\n",
    "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
    "\n",
    "        # Print a sample text after each epoch\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "\n",
    "    return train_losses, val_losses, track_tokens_seen\n",
    "\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generate_text_simple(\n",
    "            model=model, idx=encoded,\n",
    "            max_new_tokens=50, context_size=context_size\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 9.817, Val loss 9.924\n",
      "Ep 1 (Step 000005): Train loss 8.066, Val loss 8.332\n",
      "Every effort moves you,,,,,,,,,,,,.                                     \n",
      "Ep 2 (Step 000010): Train loss 6.619, Val loss 7.042\n",
      "Ep 2 (Step 000015): Train loss 6.046, Val loss 6.596\n",
      "Every effort moves you, and,, and, and,,,,, and, and,,,,,,,,,,, and,, the,, the, and,, and,,, the, and,,,,,,\n",
      "Ep 3 (Step 000020): Train loss 5.524, Val loss 6.508\n",
      "Ep 3 (Step 000025): Train loss 5.369, Val loss 6.378\n",
      "Every effort moves you, and to the of the of the picture. Gis.                                     \n",
      "Ep 4 (Step 000030): Train loss 4.830, Val loss 6.263\n",
      "Ep 4 (Step 000035): Train loss 4.586, Val loss 6.285\n",
      "Every effort moves you of the \"I the picture.                    \"I\"I the picture\"I had the picture\"I the picture and I had been the picture of\n",
      "Ep 5 (Step 000040): Train loss 3.879, Val loss 6.130\n",
      "Every effort moves you know he had been his pictures, and I felt it's by his last word.                   \"Oh, and he had been the end, and he had been\n",
      "Ep 6 (Step 000045): Train loss 3.530, Val loss 6.183\n",
      "Ep 6 (Step 000050): Train loss 2.960, Val loss 6.123\n",
      "Every effort moves you know it was his pictures--I glanced after him, I had the last word.        \"Oh, and I was his pictures--I looked.   \"I looked. \"I looked. \n",
      "Ep 7 (Step 000055): Train loss 2.832, Val loss 6.150\n",
      "Ep 7 (Step 000060): Train loss 2.104, Val loss 6.133\n",
      "Every effort moves you know the picture to me--I glanced after him, and Mrs.  \"I was no great, the fact, the fact that, the moment--as Jack himself, as his pictures--as of the picture--because he was a little\n",
      "Ep 8 (Step 000065): Train loss 1.691, Val loss 6.186\n",
      "Ep 8 (Step 000070): Train loss 1.391, Val loss 6.230\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a little: \"Yes--and by me to me to have to see a smile behind his close grayish beard--as if he had the donkey. \"There were days when I\n",
      "Ep 9 (Step 000075): Train loss 1.059, Val loss 6.251\n",
      "Ep 9 (Step 000080): Train loss 0.800, Val loss 6.278\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the fact with a laugh: \"Yes--and by me!\"  He laughed again, and threw back the window-curtains, I saw that, and down the room, and now\n",
      "Ep 10 (Step 000085): Train loss 0.569, Val loss 6.373\n",
      "Every effort moves you?\"  \"Yes--quite insensible to the irony. She wanted him vindicated--and by me!\"  He laughed again, and threw back his head to look up at the sketch of the donkey. \"There were days when I\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0004, weight_decay=0.1)\n",
    "\n",
    "num_epochs = 10\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))  # only show integer labels on x-axis\n",
    "\n",
    "    # Create a second x-axis for tokens seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(\"loss-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到模型过拟合，因为数据集太小，因此使用一定的策略降低过拟合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 控制随机性的 Decoding 策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在模型训练好之后，使用 eval 模式调用 `generate_text_simple`，每次生成的文本都是一样的。为了增加随机性，引入两种 Decoding 策略：\n",
    "- **temperature scaling**：通过调整 softmax 分布的温度参数，可以控制生成文本的随机性\n",
    "- **top-k sampling**：在生成下一个 token 时，只考虑概率最高的 k 个 token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.1 Temperature scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不再使用 `torch.argmax` 从 probas 选择概率最高的词汇输出，而是使用 `torch.multinomial` 从 probas 中按照概率分布随机选择词汇，使得输出文本具有随机性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward\n"
     ]
    }
   ],
   "source": [
    "vocab = { \n",
    "    \"closer\": 0,\n",
    "    \"every\": 1, \n",
    "    \"effort\": 2, \n",
    "    \"forward\": 3,\n",
    "    \"inches\": 4,\n",
    "    \"moves\": 5, \n",
    "    \"pizza\": 6,\n",
    "    \"toward\": 7,\n",
    "    \"you\": 8,\n",
    "} \n",
    "\n",
    "inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "# Suppose input is \"every effort moves you\", and the LLM\n",
    "# returns the following logits for the next token:\n",
    "next_token_logits = torch.tensor(\n",
    "    [4.51, 0.89, -1.90, 6.75, 1.63, -1.62, -1.89, 6.28, 1.79]\n",
    ")\n",
    "\n",
    "probas = torch.softmax(next_token_logits, dim=0)\n",
    "next_token_id = torch.argmax(probas).item()\n",
    "\n",
    "# The next generated token is then as follows:\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toward\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "next_token_id = torch.multinomial(probas, num_samples=1).item()\n",
    "print(inverse_vocab[next_token_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71 x closer\n",
      "2 x every\n",
      "0 x effort\n",
      "544 x forward\n",
      "2 x inches\n",
      "1 x moves\n",
      "0 x pizza\n",
      "376 x toward\n",
      "4 x you\n"
     ]
    }
   ],
   "source": [
    "def print_sampled_tokens(probas):\n",
    "    torch.manual_seed(123) # Manual seed for reproducibility\n",
    "    sample = [torch.multinomial(probas, num_samples=1).item() for i in range(1_000)]\n",
    "    sampled_ids = torch.bincount(torch.tensor(sample))\n",
    "    for i, freq in enumerate(sampled_ids):\n",
    "        print(f\"{freq} x {inverse_vocab[i]}\")\n",
    "\n",
    "print_sampled_tokens(probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可以通过 temperature scaling 来控制分布和选择过程，temperature scaling 只是一个花哨的词，用于将 logits 除以大于 0 的数字\n",
    "- 在应用 softmax 后，大于 1 的 temperature 将产生更均匀分布的标记概率\n",
    "- 在应用 softmax 后，小于 1 的 temperature 将产生更可信（更尖锐或更尖锐）的分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_with_temperature(logits, temperature):\n",
    "    scaled_logits = logits / temperature\n",
    "    return torch.softmax(scaled_logits, dim=0)\n",
    "\n",
    "# Temperature values\n",
    "temperatures = [1, 0.1, 5]  # Original, higher confidence, and lower confidence\n",
    "\n",
    "# Calculate scaled probabilities\n",
    "scaled_probas = [softmax_with_temperature(next_token_logits, T) for T in temperatures]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting\n",
    "x = torch.arange(len(vocab))\n",
    "bar_width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "for i, T in enumerate(temperatures):\n",
    "    rects = ax.bar(x + i * bar_width, scaled_probas[i], bar_width, label=f'Temperature = {T}')\n",
    "\n",
    "ax.set_ylabel('Probability')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(vocab.keys(), rotation=90)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"temperature-plot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.2 Tok-k sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了能够使用更高的 temperature 来增加输出多样性并降低无意义句子的概率，可以将采样的 token 限制为前 k 个最可能的标记\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/topk.webp\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top logits: tensor([6.7500, 6.2800, 4.5100])\n",
      "Top positions: tensor([3, 7, 0])\n"
     ]
    }
   ],
   "source": [
    "top_k = 3\n",
    "top_logits, top_pos = torch.topk(next_token_logits, top_k)\n",
    "\n",
    "print(\"Top logits:\", top_logits)\n",
    "print(\"Top positions:\", top_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n",
      "tensor([4.5100,   -inf,   -inf, 6.7500,   -inf,   -inf,   -inf, 6.2800,   -inf])\n"
     ]
    }
   ],
   "source": [
    "new_logits = torch.where(\n",
    "    condition=next_token_logits < top_logits[-1],\n",
    "    input=torch.tensor(float(\"-inf\")), \n",
    "    other=next_token_logits\n",
    ")\n",
    "\n",
    "print(new_logits)\n",
    "\n",
    "new_logits = torch.full_like( # create tensor containing -inf values\n",
    "   next_token_logits, -torch.inf\n",
    ")\n",
    "new_logits[top_pos] = next_token_logits[top_pos] # copy top k values into the -inf tensor\n",
    "print(new_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0615, 0.0000, 0.0000, 0.5775, 0.0000, 0.0000, 0.0000, 0.3610, 0.0000])\n"
     ]
    }
   ],
   "source": [
    "topk_probas = torch.softmax(new_logits, dim=0)\n",
    "print(topk_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5.3.3 修改 text-genration-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(model, idx, max_new_tokens, context_size, temperature=0.0, top_k=None, eos_id=None):\n",
    "\n",
    "    # For-loop is the same as before: Get logits, and only focus on last time step\n",
    "    idx = idx.to(device)\n",
    "    for _ in range(max_new_tokens):\n",
    "        idx_cond = idx[:, -context_size:]\n",
    "        with torch.no_grad():\n",
    "            logits = model(idx_cond)\n",
    "        logits = logits[:, -1, :]\n",
    "\n",
    "        # New: Filter logits with top_k sampling\n",
    "        if top_k is not None:\n",
    "            # Keep only top_k values\n",
    "            top_logits, _ = torch.topk(logits, top_k)\n",
    "            min_val = top_logits[:, -1]\n",
    "            logits = torch.where(logits < min_val, torch.tensor(float(\"-inf\")).to(logits.device), logits)\n",
    "\n",
    "        # New: Apply temperature scaling\n",
    "        if temperature > 0.0:\n",
    "            logits = logits / temperature\n",
    "\n",
    "            # Apply softmax to get probabilities\n",
    "            probs = torch.softmax(logits, dim=-1)  # (batch_size, context_len)\n",
    "\n",
    "            # Sample from the distribution\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "\n",
    "        # Otherwise same as before: get idx of the vocab entry with the highest logits value\n",
    "        else:\n",
    "            idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch_size, 1)\n",
    "\n",
    "        if idx_next == eos_id:  # Stop generating early if end-of-sequence token is encountered and eos_id is specified\n",
    "            break\n",
    "\n",
    "        # Same as before: append sampled index to the running sequence\n",
    "        idx = torch.cat((idx, idx_next), dim=1)  # (batch_size, num_tokens+1)\n",
    "\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you ever! I can fur my hostess was \"interesting\": on single one\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer),\n",
    "    max_new_tokens=15,\n",
    "    context_size=GPT_CONFIG_124M[\"context_length\"],\n",
    "    top_k=25,\n",
    "    temperature=1.4\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 加载保存模型权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    }, \n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(256, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
    "\n",
    "model = GPTModel(GPT_CONFIG_124M)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5 加载OpenAI预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.17.0\n",
      "tqdm version: 4.67.1\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", version(\"tensorflow\"))\n",
    "print(\"tqdm version:\", version(\"tqdm\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 20:53:25.012246: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from gpt_download import download_and_load_gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    }
   ],
   "source": [
    "settings, params = download_and_load_gpt2(model_size=\"124M\", models_dir=\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings: {'n_vocab': 50257, 'n_ctx': 1024, 'n_embd': 768, 'n_head': 12, 'n_layer': 12}\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings:\", settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter dictionary keys: dict_keys(['blocks', 'b', 'g', 'wpe', 'wte'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Parameter dictionary keys:\", params.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.11010301 -0.03926672  0.03310751 ... -0.1363697   0.01506208\n",
      "   0.04531523]\n",
      " [ 0.04034033 -0.04861503  0.04624869 ...  0.08605453  0.00253983\n",
      "   0.04318958]\n",
      " [-0.12746179  0.04793796  0.18410145 ...  0.08991534 -0.12972379\n",
      "  -0.08785918]\n",
      " ...\n",
      " [-0.04453601 -0.05483596  0.01225674 ...  0.10435229  0.09783269\n",
      "  -0.06952604]\n",
      " [ 0.1860082   0.01665728  0.04611587 ... -0.09625227  0.07847701\n",
      "  -0.02245961]\n",
      " [ 0.05135201 -0.02768905  0.0499369  ...  0.00704835  0.15519823\n",
      "   0.12067825]]\n",
      "Token embedding weight tensor dimensions: (50257, 768)\n"
     ]
    }
   ],
   "source": [
    "print(params[\"wte\"])\n",
    "print(\"Token embedding weight tensor dimensions:\", params[\"wte\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不同大小 GPT 模型区别：\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch05_compressed/gpt-sizes.webp?timestamp=123\" width=600px>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model configurations in a dictionary for compactness\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "# Copy the base configuration and update with specific model settings\n",
    "model_name = \"gpt2-small (124M)\"  # Example model name\n",
    "NEW_CONFIG = GPT_CONFIG_124M.copy()\n",
    "NEW_CONFIG.update(model_configs[model_name])\n",
    "# OpenAI GPT-2 需要更新的配置\n",
    "NEW_CONFIG.update({\"context_length\": 1024, \"qkv_bias\": True})\n",
    "\n",
    "gpt = GPTModel(NEW_CONFIG)\n",
    "gpt.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign(left, right):\n",
    "    if left.shape != right.shape:\n",
    "        raise ValueError(f\"Shape mismatch. Left: {left.shape}, Right: {right.shape}\")\n",
    "    return torch.nn.Parameter(torch.tensor(right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_weights_into_gpt(gpt, params):\n",
    "    gpt.pos_emb.weight = assign(gpt.pos_emb.weight, params['wpe'])\n",
    "    gpt.tok_emb.weight = assign(gpt.tok_emb.weight, params['wte'])\n",
    "    \n",
    "    for b in range(len(params[\"blocks\"])):\n",
    "        q_w, k_w, v_w = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"w\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.weight, q_w.T)\n",
    "        gpt.trf_blocks[b].att.W_key.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.weight, k_w.T)\n",
    "        gpt.trf_blocks[b].att.W_value.weight = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.weight, v_w.T)\n",
    "\n",
    "        q_b, k_b, v_b = np.split(\n",
    "            (params[\"blocks\"][b][\"attn\"][\"c_attn\"])[\"b\"], 3, axis=-1)\n",
    "        gpt.trf_blocks[b].att.W_query.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_query.bias, q_b)\n",
    "        gpt.trf_blocks[b].att.W_key.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_key.bias, k_b)\n",
    "        gpt.trf_blocks[b].att.W_value.bias = assign(\n",
    "            gpt.trf_blocks[b].att.W_value.bias, v_b)\n",
    "\n",
    "        gpt.trf_blocks[b].att.out_proj.weight = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.weight, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].att.out_proj.bias = assign(\n",
    "            gpt.trf_blocks[b].att.out_proj.bias, \n",
    "            params[\"blocks\"][b][\"attn\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].ff.layers[0].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[0].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[0].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_fc\"][\"b\"])\n",
    "        gpt.trf_blocks[b].ff.layers[2].weight = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].weight, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"w\"].T)\n",
    "        gpt.trf_blocks[b].ff.layers[2].bias = assign(\n",
    "            gpt.trf_blocks[b].ff.layers[2].bias, \n",
    "            params[\"blocks\"][b][\"mlp\"][\"c_proj\"][\"b\"])\n",
    "\n",
    "        gpt.trf_blocks[b].norm1.scale = assign(\n",
    "            gpt.trf_blocks[b].norm1.scale, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm1.shift = assign(\n",
    "            gpt.trf_blocks[b].norm1.shift, \n",
    "            params[\"blocks\"][b][\"ln_1\"][\"b\"])\n",
    "        gpt.trf_blocks[b].norm2.scale = assign(\n",
    "            gpt.trf_blocks[b].norm2.scale, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"g\"])\n",
    "        gpt.trf_blocks[b].norm2.shift = assign(\n",
    "            gpt.trf_blocks[b].norm2.shift, \n",
    "            params[\"blocks\"][b][\"ln_2\"][\"b\"])\n",
    "\n",
    "    gpt.final_norm.scale = assign(gpt.final_norm.scale, params[\"g\"])\n",
    "    gpt.final_norm.shift = assign(gpt.final_norm.shift, params[\"b\"])\n",
    "    gpt.out_head.weight = assign(gpt.out_head.weight, params[\"wte\"])\n",
    "    \n",
    "    \n",
    "load_weights_into_gpt(gpt, params)\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generate(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=NEW_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
